{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahesh-from-sirsi/All_My_AI_Work/blob/main/Exercise_Basics_of_Langchain_Using_LLMs_with_APIs_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 1: Using OpenAI Models\n"
      ],
      "metadata": {
        "id": "WFAFgej4_0Qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Python program that leverages the OpenAI GPT-4 model to create a Python function based on a user's description"
      ],
      "metadata": {
        "id": "GThxVaxw_3UR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Hint"
      ],
      "metadata": {
        "id": "m4rzQZqFA9NR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBGyKRl5_pLG"
      },
      "outputs": [],
      "source": [
        "# Example: User describes a function to calculate the factorial of a number.\n",
        "user_description = \"Write a Python function to calculate the factorial of a number.\"\n",
        "\n",
        "# Logic: Use GPT-4o to generate the Python code based on the description.\n",
        "# Hint: Initialize the model and use `invoke` to send the request."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ztomLuMKm0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 2: Using Gemini Models\n"
      ],
      "metadata": {
        "id": "orRvA_FcBvvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Python program that utilizes the Google Gemini Flash model to translate an English sentence into French. The user will provide the sentence, and the model will return the translated version."
      ],
      "metadata": {
        "id": "pP2tCKNLBzmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hint"
      ],
      "metadata": {
        "id": "e-DaUOQtKbJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: User inputs an English sentence to translate.\n",
        "english_sentence = \"Translate this sentence to French: 'Hello, how are you?'\"\n",
        "\n",
        "# Logic: Use Gemini Flash to translate the sentence into French.\n",
        "# Hint: Initialize the model and use `invoke` to send the request."
      ],
      "metadata": {
        "id": "f9RZ_QzLBwoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PcjBd7ZMKnVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 3: Using Open-Source Models\n"
      ],
      "metadata": {
        "id": "43AatAvdCy3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Python program that uses the Llama model to condense a long paragraph into a single-sentence summary. The user will provide the paragraph, and the model will return a concise version."
      ],
      "metadata": {
        "id": "IOMj-x_CCtgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hint"
      ],
      "metadata": {
        "id": "t_Xq--OAKfxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: User provides a long paragraph to summarize.\n",
        "long_paragraph = \"The Industrial Revolution was a period of major industrialization that took place during the late 1700s and early 1800s. It began in Great Britain and quickly spread throughout the world. This era saw the development of new technologies, such as the steam engine, which revolutionized transportation and manufacturing. The Industrial Revolution also led to significant social and economic changes, including urbanization and the rise of the working class.\"\n",
        "\n",
        "# Logic: Use the Llama model to generate a one-sentence summary.\n",
        "# Hint: Initialize the model and use `invoke` to send the paragraph for summarization."
      ],
      "metadata": {
        "id": "BkASnllmCuP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RrEjXpyyKnsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 4: Combining Models\n"
      ],
      "metadata": {
        "id": "Mzk-IU_hELYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Develop a Python program that uses both the OpenAI GPT-4 model and the Google Gemini Flash model to answer the same question: \"What are the key differences between Python and JavaScript?\" Compare and print their responses to see how they differ."
      ],
      "metadata": {
        "id": "w4KUePPnEPl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hint"
      ],
      "metadata": {
        "id": "FZRY0D-vKhvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question to ask both models:\n",
        "question = \"What are the key differences between Python and JavaScript?\"\n",
        "\n",
        "# Logic: Use GPT-4 and Gemini Flash to answer the question.\n",
        "# Hint: Initialize both models and use `invoke` to get their responses."
      ],
      "metadata": {
        "id": "yaYTX02rEM6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6UIXr-JKKoFw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}