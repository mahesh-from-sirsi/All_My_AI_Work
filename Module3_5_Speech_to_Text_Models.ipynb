{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahesh-from-sirsi/All_My_AI_Work/blob/main/Module3_5_Speech_to_Text_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IxX5VxNJOmr"
      },
      "source": [
        "\n",
        "# Speech 2 Text Models\n",
        "\n",
        "1. Introduction\n",
        "2. Whisper Model Overview\n",
        "   - OpenAI Documentation\n",
        "3. Setup and Installation\n",
        "   - OpenAI Package Installation\n",
        "   - API Key Configuration\n",
        "4. Audio Transcription\n",
        "   - Using Whisper Model\n",
        "5. Meeting Summarizer\n",
        "   - Meeting Summary Generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mywv7dZsQdOy"
      },
      "source": [
        "Whisper is a powerful model developed by OpenAI for converting spoken language into written text. It can handle multiple languages and various audio qualities.\n",
        "\n",
        "\n",
        "Check out the link for whisper documentation\n",
        "[OPENAI](https://platform.openai.com/docs/overview)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f5N7PU-eJRoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3fb968-8edb-4402-899e-3e29f912ccfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/948.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UHiPp4aXpn-d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-p--------\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xC4U005zK-lI"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GhfIByaRLCc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ccf406-87f6-4aba-cc98-dfd06a5fcbc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ಸ್ರೀ ಖುಲುಜ ಚರಿಂತ ಸರೋಜರಾಜ್​..! ನಿಜೆ ಮನು ಮುಕ್ಕುರು ಸುಧರಿ..! ಬರ್ಣವು ರಗುವರ್​ ಬಿಮಲ್​ ಜಸು ಜೋದಯ ಕುಪಾಲ್​ ಚರಿಂತ..! ಬುದ್ಧಿ ತನು ಜನ್ನಿಕೆ ಸುಮಿರವು ಪವನು ಕುಮರ್..! ಬಳ್ಬುದ್ಧಿ ವಿದ್ಯದೇಹು ಮೋಹಿ ಹರಹು ಕಲೇ ಶ್ವಿಕರು..! ಜೈಹನು ಮಂಗ್ಯನ್ನು ಹುಂ ಸಗರ್..! ಜೈಕ ಪಿಸ್ತಿಹುನ್ನು ಲೋಕು ಜಾಗರ್..! ರಂದೂ ತತುಲಿತ್ತು ಬಲ್ದಾಮಾ..! ಅಂಜನಿ ಪುತ್ರ ಪವನು ಸೋದ್ನಮ..! ಮಹವಿರ್ ವಿಕ್ರಮ್ ಬಜರಂಗಿ..! ಕುಮತಿ ನಿವಾರ್ ಸುಮತಿಕೆ ಸಂಗಿ..! ಕಂಚನ್ ಬರನ್ ಬಿರಾಜ್ ಸುಬೆ ಸಾರ್..! ಕಾನನ್ ಕುಂದಲ್ ಕುಂಚಿಟ್ ಕೇಸಾರ್..! ಹತ್ ವಜರಾ ಓರ್ ತಜಬಿರಾಜೆ..! ಕಾಂಧೇ ಮುಞ್ಜು ಜಾನೆ ಉಂಸಾಜೆ..! ಜಯಿ ಹನು ಮಂಜನ್ ಗುನ್ ಸಗರ್..! ಜಯಿ ಕಪಿಸ್ತಿ ಹೂಣು ಲೋಕ್ ಪುಜಾಗರ್..! ರಂದೂ ತತುಲಿತ್ ಬಲ್ಧಾಮಾ..! ಅಂಜಾನಿ ಪುತ್ರ ಪಾವನ್ ಸೂತ್ ನಮಾ..! ಜಯಿ ಹನು ಮಂಜನ್ ಗುನ್ ಸಗರ್..! ಜಯಿ ಕಪಿಸ್ತಿ ಹೂಣು ಲೋಕ್ ಪುಜಾಗರ್..! ರಂದೂ ತತುಲಿತ್ ಬಲ್ಧಾಮಾ..! ಅಂಜಾನಿ ಪುತ್ರ ಪಾವನ್ ಸೂತ್ ನಮಾ..!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file = open(\"/content/Shree Hanuman Chalisa.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file,\n",
        "  response_format=\"text\",\n",
        "  #language=\"kn\"\n",
        ")\n",
        "\n",
        "print(transcript)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqrrs58FQjr0"
      },
      "source": [
        "### Meeting Summariser using Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D0sdmNXNLXhq"
      },
      "outputs": [],
      "source": [
        "# Summarise the meeting\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "def summarise_meeting(meeting_audio):\n",
        "  audio_file = open(meeting_audio, \"rb\")\n",
        "  transcript = client.audio.transcriptions.create(\n",
        "                        model=\"whisper-1\",\n",
        "                        file=audio_file,\n",
        "                        response_format=\"text\"\n",
        "                      )\n",
        "\n",
        "  llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
        "  result = llm.invoke(f\"\"\" Summarise the below transcript into 5 bullet points\n",
        "                  {transcript}\n",
        "  \"\"\")\n",
        "\n",
        "  return result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrSEdXPmPQHq",
        "outputId": "373e6c15-1eb4-4f26-be42-1a1f160a21f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. The verse begins with an invocation to the Guru, emphasizing the cleansing and purifying qualities of the Guru's feet, which reflect the purity of one's own mind.\n",
            "\n",
            "2. It highlights the virtues of Lord Rama, specifically his divine grace and the benefits of remembering him, indicating the strength and intellect gained from devotion.\n",
            "\n",
            "3. The text praises Hanuman, describing him as a brave and powerful figure, the son of the wind god, who symbolizes knowledge and wisdom.\n",
            "\n",
            "4. It celebrates Hanuman's attributes, including his loyalty, strength, and the ability to dispel ignorance and negativity, portraying him as a companion of intellect and virtue.\n",
            "\n",
            "5. The repeated chanting of Hanuman’s name reinforces his significance in overcoming obstacles and invoking spiritual strength, with a call for blessings and guidance from him.\n"
          ]
        }
      ],
      "source": [
        "print(summarise_meeting(\"/content/Shree Hanuman Chalisa.mp3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KUBXVHe_Q7Z5"
      },
      "outputs": [],
      "source": [
        "def crash_course_function(meeting_audio):\n",
        "  audio_file = open(meeting_audio, \"rb\")\n",
        "  transcript = client.audio.transcriptions.create(\n",
        "                        model=\"whisper-1\",\n",
        "                        file=audio_file,\n",
        "                        response_format=\"text\"\n",
        "                      )\n",
        "\n",
        "  llm = ChatOpenAI(model = \"gpt-3.5-turbo\")\n",
        "  result = llm.invoke(f\"\"\" Below is the transcript of the course I want to purchase. Give me 3 questions I can ask the founder regarding the course\n",
        "                  {transcript}\n",
        "  \"\"\")\n",
        "\n",
        "  return result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l3zhTqOjUFxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458091d8-8e97-4016-eb1d-4f72dd8cd360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Can you explain the structure of the course and how it will help students achieve their goals?\n",
            "2. What kind of support and resources will be provided to students throughout the duration of the course?\n",
            "3. Are there any prerequisites or recommended background knowledge needed for students to successfully complete the course?\n"
          ]
        }
      ],
      "source": [
        "print(crash_course_function(\"/content/Shree Hanuman Chalisa.mp3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ULtx1xBFURKb"
      },
      "outputs": [],
      "source": [
        "def sales_call_analyser(meeting_audio):\n",
        "  audio_file = open(meeting_audio, \"rb\")\n",
        "  transcript = client.audio.transcriptions.create(\n",
        "                        model=\"whisper-1\",\n",
        "                        file=audio_file,\n",
        "                        response_format=\"text\"\n",
        "                      )\n",
        "\n",
        "  llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
        "  result = llm.invoke(f\"\"\" Below is the transcript of the sales call.\n",
        "                  {transcript}\n",
        "\n",
        "                      Give me the following answer\n",
        "                      1. Is the customer likely to purchase?\n",
        "                      2. Overall Intent\n",
        "                      3. Feedback for the sales person\n",
        "  \"\"\")\n",
        "\n",
        "  return result.content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sales_call_analyser(\"/content/Shree Hanuman Chalisa.mp3\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwGyGbhRfMhe",
        "outputId": "e23c0c28-41fe-47cd-f69a-a26917da36bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The transcript you provided appears to be a devotional song or prayer rather than a sales call. Due to the nature of the content, it doesn't provide any clear indicators of a customer interaction, purchasing intent, or feedback relevant to a sales interaction.\n",
            "\n",
            "However, if we were to analyze this as a typical sales conversation (assuming it metaphorically represents a customer expressing interest), we could respond as follows based on generic principles:\n",
            "\n",
            "1. **Is the customer likely to purchase?**\n",
            "   - Since there are no signs of product interest or specific needs articulated by the customer in the transcript, it's difficult to ascertain purchasing intent. Typically, clear needs or queries about specific products would indicate a likelihood to purchase.\n",
            "\n",
            "2. **Overall Intent:**\n",
            "   - The overall intent, based on the nature of the content, seems to be devotional and spiritual rather than commercial. Therefore, it does not appear to have an intent related to sales or purchasing.\n",
            "\n",
            "3. **Feedback for the sales person:**\n",
            "   - If we consider the sales person’s role in this context, they should focus on engaging the customer by addressing their specific needs or interests clearly and facilitating a conversation that leads to a purchasing decision. In a traditional sales call, the sales person should ensure they are asking open-ended questions, actively listening, and responding to any concerns or requirements the customer may have.\n",
            "\n",
            "If this was meant to be a sales call, please provide more relevant content or context to enable a more accurate assessment.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}