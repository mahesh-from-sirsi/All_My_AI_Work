{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahesh-from-sirsi/All_My_AI_Work/blob/main/Module3_5_Exercise_Speech_to_Text_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQSeMm7cRFdJ"
      },
      "source": [
        "## Exercise 1: Create a \"Language Translator App\"\n",
        "\n",
        "Task: Build a Language Translator App that transcribes an audio file in one language and translates the transcribed text into another language using OpenAI's Whisper and GPT models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hint:"
      ],
      "metadata": {
        "id": "ccU7JRKbTnfl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6-IxxoGRFdL"
      },
      "outputs": [],
      "source": [
        "#Use the client.audio.transcriptions.create() function for transcription.\n",
        "#Use the ChatOpenAI model to translate the text.\n",
        "\n",
        "def language_translator_app(audio_file: str, target_language: str) -> str\n",
        "    # Step 1: Transcribe the audio file\n",
        "\n",
        "    # Step 2: Translate the transcribed text\n",
        "\n",
        "# Complete the code"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z3uooCprYva2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT7NvCffRFdM"
      },
      "source": [
        "## Exercise 2: Create a \"Podcast Highlight Generator\"\n",
        "\n",
        "Task: Build a Podcast Highlight Generator that extracts key highlights or interesting moments from a podcast audio file using Whisper and GPT.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hint"
      ],
      "metadata": {
        "id": "C7mXO1xrWv7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Use the client.audio.transcriptions.create() function for transcription.\n",
        "# Step 2: Use the ChatOpenAI model to generate highlights.\n",
        "\n",
        "def podcast_highlight_generator(audio_file: str) -> str:\n",
        "    # Step 1: Transcribe the podcast audio\n",
        "\n",
        "    # Step 2: Generate highlights using GPT\n",
        "\n",
        "#Complete the code"
      ],
      "metadata": {
        "id": "PdthFFsSZngR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PUU1cFDnseUf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}