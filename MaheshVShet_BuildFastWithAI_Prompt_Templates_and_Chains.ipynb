{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahesh-from-sirsi/All_My_AI_Work/blob/main/MaheshVShet_BuildFastWithAI_Prompt_Templates_and_Chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd-sh-8ySTM2"
      },
      "source": [
        "## Installing libraries\n",
        "\n",
        "\n",
        "Installing essential Python libraries who allows you to work with LLMs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain==0.3.4 langchain-openai==0.2.12 langchain-google-genai==2.0.1"
      ],
      "metadata": {
        "id": "GpD5Fsqt0Zv9",
        "outputId": "75116bdc-ff1e-4c02-b671-5f6c5706cde0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.4\n",
            "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-openai==0.2.12\n",
            "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-google-genai==2.0.1\n",
            "  Downloading langchain_google_genai-2.0.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.4) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.4) (2.0.43)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.4) (3.12.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.4) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.4) (0.3.11)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.4)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2.0.0,>=1.26.0 (from langchain==0.3.4)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.4) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.4) (2.32.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.4) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.12) (1.106.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.12) (0.11.0)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai==2.0.1) (0.8.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.4) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.4) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.4) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.4) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.4) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.4) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.4) (1.20.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (2.181.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (1.26.1)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain==0.3.4)\n",
            "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.73-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.71-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.70-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain==0.3.4) (1.33)\n",
            "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.12->langchain==0.3.4)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.4)\n",
            "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.4) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.4) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.4) (1.0.0)\n",
            "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pip>=25.2 (from langchain-text-splitters<0.4.0,>=0.3.0->langchain==0.3.4)\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.4)\n",
            "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.4) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.4) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.4) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.4) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2024.11.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.4) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.4) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain==0.3.4) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (0.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.1) (0.6.1)\n",
            "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: packaging, numpy, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-google-genai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URfJBVwtq4Dp"
      },
      "source": [
        "\n",
        "### Storing API keys\n",
        "\n",
        "API keys allow you access LLMs by the providers (OpenAI, Google, Anthropic, etc). In this lecture, we will be using OpenAI models (gpt-3.5-turbo, gpt4) and Google's LLMs (Gemini models)\n",
        "\n",
        "- Get OpenAI API key: https://platform.openai.com/account/api-keys\n",
        "- Get Google API key: https://aistudio.google.com (FREE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx_d9XJFm77k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set up API keys for OpenAI and Google\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"\"\n",
        "\n",
        "os.environ['GOOGLE_API_KEY']  = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14mklUIFrP5A"
      },
      "source": [
        "### Using LLM to run a query using API\n",
        "\n",
        "In this code, you will understand how to send a prompt to an LLM via an API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBteLVmqnOCd"
      },
      "outputs": [],
      "source": [
        "# Import ChatOpenAI module\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize OpenAI's GPT 4o mini model\n",
        "gpt4o_mini_model = ChatOpenAI(model_name = \"gpt-4o-mini\")  # use \"gpt-4o\" for new GPT-4 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiGYMiICpo9L",
        "outputId": "dc9b6593-2400-4273-a61a-77431ffa9ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Transformer architecture is a type of neural network model that has revolutionized natural language processing (NLP) and other sequence-based tasks. Introduced in the paper \"Attention is All You Need\" by Vaswani et al. in 2017, the Transformer model is notable for its use of self-attention mechanisms and its ability to handle long-range dependencies in data without relying on recurrent structures.\n",
            "\n",
            "### Key Components of the Transformer Architecture\n",
            "\n",
            "1. **Input Representation:**\n",
            "   - **Tokenization:** The input text is first tokenized into smaller units (tokens), such as words or subwords.\n",
            "   - **Positional Encoding:** Since the Transformer does not have a built-in notion of sequence order, positional encodings are added to the token embeddings to provide information about the position of tokens in the sequence.\n",
            "\n",
            "2. **Encoder-Decoder Structure:**\n",
            "   - The Transformer consists of an encoder and a decoder.\n",
            "   - **Encoder:** Processes the input sequence and generates a continuous representation of it.\n",
            "   - **Decoder:** Takes the encoder's output and generates the output sequence (e.g., translated text).\n",
            "\n",
            "3. **Encoder:**\n",
            "   - The encoder is composed of multiple identical layers (usually 6 to 12).\n",
            "   - Each layer has two main components:\n",
            "     - **Multi-Head Self-Attention:** This mechanism allows the model to weigh the importance of different tokens in the input sequence. It computes attention scores based on the relationships between all tokens, enabling the model to focus on relevant parts of the input.\n",
            "     - **Feed-Forward Neural Network:** After the attention mechanism, the output is passed through a feed-forward neural network, which applies a non-linear transformation to each position independently.\n",
            "   - Each of these components is followed by layer normalization and residual connections, which help stabilize training and improve gradient flow.\n",
            "\n",
            "4. **Decoder:**\n",
            "   - Like the encoder, the decoder also consists of multiple identical layers.\n",
            "   - Each decoder layer has three main components:\n",
            "     - **Masked Multi-Head Self-Attention:** This allows the decoder to attend to previous tokens in the output sequence while preventing access to future tokens (important for tasks like text generation).\n",
            "     - **Multi-Head Attention over Encoder Output:** This enables the decoder to focus on relevant parts of the encoder's output, integrating information from the input sequence.\n",
            "     - **Feed-Forward Neural Network:** Similar to the encoder, this applies a non-linear transformation to the output.\n",
            "   - The decoder also employs layer normalization and residual connections.\n",
            "\n",
            "5. **Final Linear and Softmax Layer:**\n",
            "   - The output from the decoder is transformed into a probability distribution over the vocabulary using a linear layer followed by a softmax activation function, allowing the model to predict the next token in the sequence.\n",
            "\n",
            "### Advantages of the Transformer Architecture\n",
            "\n",
            "- **Parallelization:** Unlike recurrent neural networks (RNNs), which process sequences one step at a time, Transformers can process all tokens in a sequence simultaneously. This leads to significant speed improvements during training.\n",
            "- **Long-Range Dependencies:** The self-attention mechanism allows the model to capture long-range dependencies more effectively than RNNs, which struggle with vanishing gradients.\n",
            "- **Scalability:** Transformers can be scaled up easily by increasing the number of layers or the size of the model, which has led to very large models like GPT-3 and BERT.\n",
            "\n",
            "### Applications\n",
            "\n",
            "Transformers have been widely adopted in various NLP tasks, including:\n",
            "- Translation\n",
            "- Text summarization\n",
            "- Question answering\n",
            "- Sentiment analysis\n",
            "- Language modeling\n",
            "\n",
            "The Transformer architecture has also been adapted and extended to other domains, such as computer vision (Vision Transformers) and audio processing, further demonstrating its versatility and effectiveness across diverse tasks.\n"
          ]
        }
      ],
      "source": [
        "# Example of using the GPT-4o mini model\n",
        "response = gpt4o_mini_model.invoke(\"Explain transformers architecture.\")\n",
        "\n",
        "# Display the output\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHTaQ_hYSOPX",
        "outputId": "54e121bd-1acf-4f8f-f4ab-1612e9094c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! Here are three tweets about World War I:\n",
            "\n",
            "1. 🌍💔 Today, we remember the millions who sacrificed their lives during World War I. A conflict that reshaped nations and ideologies, reminding us of the cost of war. Let’s honor their legacy by promoting peace and understanding. #WWI #LestWeForget\n",
            "\n",
            "2. 🕊️✨ As we reflect on World War I, let's not forget the technological advancements that emerged, from tanks to airplanes. This was a war that changed the face of combat forever. What innovations do you think had the most impact? #WWI #HistoryMatters\n",
            "\n",
            "3. 📚🖋️ World War I was not just a battle of armies; it was a clash of cultures and ideas. Literature from this era, like the works of Wilfred Owen and Erich Maria Remarque, gives us profound insights into the human experience of war. What’s your favorite WWI book? #WWI #LiteraryLegacy\n"
          ]
        }
      ],
      "source": [
        "response = gpt4o_mini_model.invoke(\"Generate 3 tweets on World War I\")\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIAnh1GvSd5r"
      },
      "source": [
        "### Using Gemini Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqBkrp8Y1dff",
        "outputId": "5afd11b0-d445-4635-ed25-5a461e33b9b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/satvikp/Desktop/GenAI_Bootcamp/notebooks/genai-bootcamp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Using Google Models (Gemini Pro)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Initialize Google's Gemini model\n",
        "gemini_model = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash-latest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0P6tlqiEMtC",
        "outputId": "f8c8a010-eb80-412b-f2c3-8a1d622de143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## World War 1 Tweets:\n",
            "\n",
            "**1.**  #WW1 Remember the cost of war. 100 years ago, millions lost their lives in the Great War. Let's learn from the past and strive for peace. #NeverForget #History \n",
            "\n",
            "**2.**  #WW1Fact  The first use of tanks in combat was during the Battle of the Somme in 1916.  These \"land ships\" were supposed to break the stalemate but faced many challenges.  #History #MilitaryHistory \n",
            "\n",
            "**3.**  #WW1  The war not only had devastating consequences on the battlefield but also on the home front.  #WW1  #History  #SocialHistory \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example of using the Gemini model\n",
        "response = gemini_model.invoke(\"Give me 3 tweets on World War 1\")\n",
        "\n",
        "# Display the output\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZAfJwFctDrp"
      },
      "source": [
        "### Using Prompt Template\n",
        "\n",
        "Prompt templates are pre-designed patterns for creating prompts, with placeholders for specific inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISLTNzK8qWfw"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "# Create prompt template for generating tweets\n",
        "\n",
        "tweet_template = \"Give me {number} tweets on {topic}\"\n",
        "\n",
        "tweet_prompt = PromptTemplate(template = tweet_template, input_variables = ['number', 'topic'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y9Yp6sOzt7ED",
        "outputId": "64831e02-22d5-47a3-c307-e2652ac00bc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Give me 7 tweets on Submarine'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tweet_template.format(number =7, topic = \"Submarine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKZsu4AOSzmg"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "# Define the template for product requirement\n",
        "product_requirement_template = \"\"\"\n",
        "Create a product requirement document for a {product_type}.\n",
        "The document should include the following details:\n",
        "1. Target audience: {target_audience}\n",
        "2. Key features: {key_features}\n",
        "3. Budget: {budget}\n",
        "\"\"\"\n",
        "\n",
        "# Create the PromptTemplate instance\n",
        "product_requirement_prompt = PromptTemplate(\n",
        "    template=product_requirement_template,\n",
        "    input_variables=['product_type', 'target_audience', 'key_features', 'budget']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGRchxDvSzmg",
        "outputId": "2f17f33b-6602-441e-f28e-3b750debe73d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Create a product requirement document for a smartphone.\n",
            "The document should include the following details:\n",
            "1. Target audience: young professionals\n",
            "2. Key features: long battery life, high-quality camera, 5G support\n",
            "3. Budget: $500 - $800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inputs for product requirement\n",
        "product_type = \"smartphone\"\n",
        "target_audience = \"young professionals\"\n",
        "key_features = \"long battery life, high-quality camera, 5G support\"\n",
        "budget = \"$500 - $800\"\n",
        "\n",
        "# Generating the prompt\n",
        "prompt = product_requirement_prompt.format(\n",
        "    product_type=product_type,\n",
        "    target_audience=target_audience,\n",
        "    key_features=key_features,\n",
        "    budget=budget\n",
        ")\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yypnESQuuqRs"
      },
      "source": [
        "### Using LLM Chains\n",
        "\n",
        "LLM Chains are sequences of prompts and language models combined to perform more complex tasks.\n",
        "\n",
        "LLM Chain = Prompt Template | LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k02dkG3uuPPU"
      },
      "outputs": [],
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "\n",
        "# Create LLM chain using the prompt template and model\n",
        "tweet_chain = tweet_prompt | gpt4o_mini_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS78bwxx43ud",
        "outputId": "19ee07c0-ecc8-4680-e556-4eec82a16619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here are five tweets that address various aspects of wars in the Middle East:\n",
            "\n",
            "1. 🌍 \"The Middle East has been a theater of conflict for decades, where geopolitical interests clash with the hopes of millions. It's time for dialogue and diplomacy to take center stage! #PeaceInTheMiddleEast #EndTheWar\"\n",
            "\n",
            "2. 🕊️ \"Every conflict in the Middle East echoes the struggles of ordinary people. Let's remember the civilians caught in the crossfire and advocate for their rights and safety. #HumanRights #MiddleEast\"\n",
            "\n",
            "3. 🔍 \"As tensions rise in the Middle East, we must ask: what lessons can we learn from the past? History shows us that lasting peace requires understanding and collaboration, not just military might. #LessonsFromHistory #ConflictResolution\"\n",
            "\n",
            "4. 📊 \"The humanitarian impact of wars in the Middle East is staggering. Millions displaced, countless lives lost—it's crucial we support organizations working on the ground to provide relief and rebuild lives. #HumanitarianAid #SupportTheCause\"\n",
            "\n",
            "5. ✈️ \"Military interventions in the Middle East often lead to unintended consequences. It's essential to rethink our approach and prioritize diplomatic solutions that foster stability and growth. #RethinkIntervention #DiplomacyFirst\"\n",
            "\n",
            "Feel free to use or modify these tweets as you see fit!\n"
          ]
        }
      ],
      "source": [
        "# Example of using the LLM chain\n",
        "response = tweet_chain.invoke({\"number\" : 5, \"topic\" : \"Wars in Middle East\"})\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGEK7NAvk3QZ",
        "outputId": "da42e940-5247-410d-f534-788a52fa8404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here are 10 tweets on road safety that you can use or get inspiration from:\n",
            "\n",
            "1. 🚦 **Buckle Up!** Always wear your seatbelt. It’s your best protection on the road. #RoadSafety #BuckleUp\n",
            "\n",
            "2. 🛑 **Stop, Look, and Listen!** Before crossing the street, make sure it’s safe. Your life matters! #PedestrianSafety #RoadSafety\n",
            "\n",
            "3. 🚲 **Stay Alert on Two Wheels!** Cyclists, always wear a helmet and follow traffic rules. Safety first! #CyclingSafety #RoadSafety\n",
            "\n",
            "4. 📱 **Put Down the Phone!** Distracted driving is dangerous. Stay focused and keep your eyes on the road. #NoDistractions #RoadSafety\n",
            "\n",
            "5. 🌧️ **Drive to Conditions!** Rain or fog can make roads slippery. Adjust your speed and stay safe! #WeatherAwareness #RoadSafety\n",
            "\n",
            "6. 🏍️ **Watch for Motorcycles!** They can be hard to see. Always check your blind spots before changing lanes. #ShareTheRoad #RoadSafety\n",
            "\n",
            "7. 👶 **Child Safety First!** Ensure kids are in the right car seats for their age and size. #ChildSafety #RoadSafety\n",
            "\n",
            "8. 🚧 **Follow the Signs!** Traffic signals and road signs keep everyone safe. Obey them at all times. #TrafficRules #RoadSafety\n",
            "\n",
            "9. 🐾 **Watch for Wildlife!** Be extra cautious in areas known for animal crossings, especially at dusk and dawn. #WildlifeSafety #RoadSafety\n",
            "\n",
            "10. 🚨 **Emergency Preparedness!** Keep a safety kit in your vehicle. Be ready for any situation on the road! #BePrepared #RoadSafety\n",
            "\n",
            "Feel free to customize these tweets to better match your style or audience!\n"
          ]
        }
      ],
      "source": [
        "# Example of using the LLM chain\n",
        "\n",
        "response = tweet_chain.invoke({\"number\" : 10, \"topic\" : \"Road Safety\"})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3l23b_WHXlB"
      },
      "outputs": [],
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "# Create LLM chain using the prompt template and model\n",
        "prd_chain = product_requirement_prompt | gpt4o_mini_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGdL3MynSzmg",
        "outputId": "95b63e6a-b50e-4423-f4b8-68ae92c8717a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Product Requirement Document (PRD) for Smartphone\n",
            "\n",
            "## 1. Overview\n",
            "This document outlines the requirements for a new smartphone targeted at young professionals. The smartphone will emphasize long battery life, high-quality camera capabilities, and 5G support while remaining within a budget of $500 to $800.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Target Audience\n",
            "**Young Professionals**  \n",
            "- **Demographics**: Ages 25-35, tech-savvy individuals, often living in urban areas.  \n",
            "- **Psychographics**: Value convenience, quality, and productivity. They seek devices that enhance their professional and personal lifestyles.  \n",
            "- **Usage Patterns**: Frequently use smartphones for communication, social media, photography, navigation, and productivity tools.\n",
            "\n",
            "---\n",
            "\n",
            "## 3. Key Features\n",
            "\n",
            "### 3.1 Long Battery Life\n",
            "- **Battery Capacity**: Minimum 4500 mAh.\n",
            "- **Battery Life**: Minimum 24 hours of mixed-use on a single charge, with a standby time of at least 48 hours.\n",
            "- **Fast Charging**: Support for 30W fast charging and at least 15W wireless charging.\n",
            "- **Power Management**: Intelligent battery management software to optimize usage according to user habits.\n",
            "\n",
            "### 3.2 High-Quality Camera\n",
            "- **Main Camera**: Minimum 48 MP with optical image stabilization (OIS).\n",
            "  - Features: Night mode, portrait mode, and 4K video recording.\n",
            "- **Front Camera**: Minimum 16 MP with AI enhancements for better selfies and video calls.\n",
            "  - Features: Wide-angle lens and portrait mode.\n",
            "- **Camera Software**: User-friendly interface with advanced editing features and AI enhancements for optimal photo quality.\n",
            "- **Additional Features**: Dual-camera setup for enhanced photographic capabilities (e.g., ultra-wide, macro).\n",
            "\n",
            "### 3.3 5G Support\n",
            "- **Network Compatibility**: Support for both Sub-6 and mmWave bands to ensure robust connectivity in various environments.\n",
            "- **Future-Proofing**: Compatible with upcoming 5G technologies and standards to ensure longevity of the device.\n",
            "\n",
            "---\n",
            "\n",
            "## 4. Design Requirements\n",
            "- **Form Factor**: Sleek and lightweight design, easy to hold and use with one hand.\n",
            "- **Display**: Minimum 6.5-inch Full HD+ AMOLED display for vibrant colors and deep blacks.\n",
            "- **Build Quality**: Premium materials (e.g., glass back, aluminum frame) for durability and aesthetics.\n",
            "- **Color Options**: At least three color variants tailored to young professionals (e.g., black, silver, and a vibrant color).\n",
            "\n",
            "---\n",
            "\n",
            "## 5. Performance Requirements\n",
            "- **Processor**: Minimum Qualcomm Snapdragon 7xx series or equivalent for smooth multitasking and gaming performance.\n",
            "- **RAM**: Minimum 6 GB for optimal performance in multitasking and resource-intensive applications.\n",
            "- **Storage Options**: Minimum 128 GB with an option for expandable storage via microSD.\n",
            "\n",
            "---\n",
            "\n",
            "## 6. Software Requirements\n",
            "- **Operating System**: Android 12 or higher with a clean, bloatware-free experience.\n",
            "- **Updates**: Commitment to regular software updates for at least three years post-launch.\n",
            "- **User Interface**: Intuitive and user-friendly interface with customizable features.\n",
            "\n",
            "---\n",
            "\n",
            "## 7. Budget\n",
            "- **Price Range**: The smartphone should be priced between $500 and $800 to ensure accessibility for the target market while maintaining quality and performance standards.\n",
            "\n",
            "---\n",
            "\n",
            "## 8. Competitive Analysis\n",
            "- **Direct Competitors**: Analyze comparable devices from brands like OnePlus, Google Pixel, Samsung, and Xiaomi.\n",
            "- **Differentiation**: Focus on superior battery life, camera quality, and unique software features to distinguish the product within the market.\n",
            "\n",
            "---\n",
            "\n",
            "## 9. Launch Strategy\n",
            "- **Marketing**: Targeted digital marketing campaigns focusing on social media platforms frequented by young professionals (e.g., Instagram, LinkedIn).\n",
            "- **Partnerships**: Collaborate with influencers and tech reviewers to build credibility and visibility.\n",
            "- **Availability**: Launch through online channels as well as select retail stores to maximize reach.\n",
            "\n",
            "---\n",
            "\n",
            "## 10. Timeline\n",
            "- **Project Kickoff**: [Date]\n",
            "- **Design and Prototyping Phase**: [Date]\n",
            "- **Testing Phase**: [Date]\n",
            "- **Launch Date**: [Date]\n",
            "\n",
            "---\n",
            "\n",
            "## 11. Conclusion\n",
            "This product requirement document serves as a comprehensive guideline for the development of a smartphone tailored to young professionals. By focusing on long battery life, high-quality camera capabilities, and 5G support, we aim to meet the needs of our target audience while maintaining a competitive price point.\n"
          ]
        }
      ],
      "source": [
        "product_type = \"smartphone\"\n",
        "target_audience = \"young professionals\"\n",
        "key_features = \"long battery life, high-quality camera, 5G support\"\n",
        "budget = \"$500 - $800\"\n",
        "\n",
        "response = prd_chain.invoke({\"product_type\" : product_type, \"target_audience\" : target_audience, \"key_features\" : key_features, \"budget\" : budget})\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kdfoy5rSzmh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IWnUZFtHX4G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}